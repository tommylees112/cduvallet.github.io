title: Reflections on Amazon same-day delivery excluding Roxbury
link: https://claireduvallet.wordpress.com/2018/01/07/reflections-on-amazon-same-day-delivery-excluding-roxbury/
author: cduvallet
description: 
post_id: 1447
created: 2018/01/07 08:56:52
created_gmt: 2018/01/07 08:56:52
comment_status: open
post_name: reflections-on-amazon-same-day-delivery-excluding-roxbury
status: publish
post_type: post

# Reflections on Amazon same-day delivery excluding Roxbury

One of the keynotes discussing disparities in big data at this year's [Pacific Symposium on Biocomputing](http://psb.stanford.edu) pointed to a [Bloomberg article](https://www.bloomberg.com/graphics/2016-amazon-same-day/) about Amazon's same-day delivery areas: in Boston (at the time of writing), all neighborhoods surrounding Roxbury were eligible for same-day delivery but Roxbury was not. ![Screen Shot 2018-01-06 at 10.38.11 PM](https://claireduvallet.files.wordpress.com/2018/01/screen-shot-2018-01-06-at-10-38-11-pm.png) I [tweeted](https://twitter.com/cduvallet/status/949452472942174208) that when I saw this, my jaw literally dropped (which it did) - not because I'm surprised that this was the case, but because I was so surprised to see such a clear irrefutable example of bias in algorithms. Like, there is no Occam's razor explanation you can give for the map above, not if you're being serious with yourself.  A couple things stuck out to me in the Bloomberg article. First: 

> There’s no evidence that Amazon makes decisions on where to deliver based on race. Berman [Amazon’s vice president for global communications] says the ethnic composition of neighborhoods isn’t part of the data Amazon examines when drawing up its maps. ... Amazon, he says, has a “radical sensitivity” to any suggestion that neighborhoods are being singled out by race. “Demographics play no role in it. Zero.”

Here's the thing. If race isn't part of your data, then you can't control for it and your decisions will end up being based on it. It's irresponsible to say "we didn't explicitly use race in our algorithms therefore race is not affecting our results" when we know that race affects every aspect of American society. I'd argue that arguing otherwise demonstrates a "radical **insensitivity**" to the role that race plays in America. Another completely unsatisfying cop-out: 

> Amazon says it’s misleading to scrutinize its current delivery areas so closely, because the service is new and evolving. Eventually, coverage will extend to every ZIP code in same-day cities, says Berman. The service is indeed expanding. Since Bloomberg first contacted Amazon for this article in February, the company announced 12 new same-day cities. As it adds locations, however, Amazon has yet to extend coverage to excluded majority-black ZIP codes in the existing cities with gaps in service. How long will those customers have to wait to get the full benefits of their Prime membership? Berman says there’s no set timetable: “We’ll get there.”

No, by now you've made it clear that you won't get there on your own. It's also _so obvious_ that whatever excuses Amazon is giving about what's preventing them from expanding their business equitably are just bullshit: since the Bloomberg article was published in April, Amazon has expanded coverage to the previously excluded predominantly black neighborhoods in Boston, New York City, and Chicago. It's so clearly a question of desire and will and not one of logistics. I love this article because it identified a problem, demonstrated it with data (and beautiful visualizations), and resulted in action. More of this, less of bullshit excuses. So to rapidly expanding businesses who are shaping our culture: you have a responsibility to do better. Recognize that ignoring something (like race) doesn't make it go away and that just because something isn't in your data doesn't mean it's not in your data. Care more, act thoughtfully, and do better for everyone.