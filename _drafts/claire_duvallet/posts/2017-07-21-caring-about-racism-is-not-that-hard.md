---
title: Caring about racism is not that hard
#link: https://claireduvallet.wordpress.com/2017/07/21/caring-about-racism-is-not-that-hard/
permalink: /posts/2017/07/caring-about-racism-is-not-that-hard
date: 2017-07-21
tags:
    - data-science
    - diversity
---


I saw this article today, ["How to make a racist AI without really trying"](https://blog.conceptnet.io/2017/07/13/how-to-make-a-racist-ai-without-really-trying/), and love so many things about it! My favorite quotes:

> Making a non-racist classifier is only a little bit harder than making a racist classifier. The fixed version can even be more accurate at evaluations. But to get there, you have to know about the problem, and you have to be willing to not just use the first thing that works.

> Some people expect that fighting algorithmic racism is going to come with some sort of trade-off. There's no trade-off here. You can have data that's better and less racist. You can have data that's better because it's less racist. There was never anything "accurate" about the overt racism that word2vec and GloVe learned.

To me, the tl;dr of these (and all other "we improved our diversity-related problem!") articles is: it really isn't that hard to be better, _if you care_. That last part though, that's what'll get you.  

An example of an organization who didn't care, and royally fucked up: [GitHub](http://where.coraline.codes/blog/my-year-at-github/). And of course the [Uber story](https://www.susanjfowler.com/blog/2017/2/19/reflecting-on-one-very-strange-year-at-uber) that everyone better have read by now.

An example of an organization who did care, and who put their money where their mouth is and saw _gasp! magical_ improvements: [Pinterest](https://hbr.org/2017/07/what-we-learned-from-improving-diversity-rates-at-pinterest).

As I'm entering my third year working on diversity initiatives in my department, I'm finding myself stopped up against this wall so many times. It's not _that_ hard to rethink how you do admissions or messaging or faculty recruitment, if you only care enough.  It's honestly not that hard to organize a conference with predominantly non-white male speakers - [I promise](https://claireduvallet.wordpress.com/2017/02/21/microbial-centennial-of-men/)! If you care, then you'll try harder and be more thoughtful - and that's usually a really good first step to get you moving! It's not that hard to ensure that your [professor's acknowledgements](https://claireduvallet.wordpress.com/2017/04/18/professor-superlatives/) are not completely gendered - if you care, then you'll try harder and be more thoughtful!

In my brief exposure to diversity, equity, and inclusion initiatives in higher education, I've been baffled at how little critical thinking seems to be happening from people at the top. [Certain groups](http://fisk-vanderbilt-bridge.org/) are definitely thinking critically about how to improve things, but generally speaking diversity and equity are not things that faculty care about and so they're not something that they think about with the problem-solving parts of their brains. Which is a shame, because that's literally supposed to be the strongest parts of their brains.

I really do believe that if faculty actually cared about diversity and equity the way they care about their research, the racial and gender disparities in STEM higher education could be improved so quickly. The problem is that that would require caring enough to put in the energy to learn about the systemic problems and brainstorm solutions, and then caring enough to actually implement and evaluate those solutions. Basically what you'd do for your research project, except for your community. More importantly though, and a much larger obstacle in my view, is that improving diversity in STEM higher education would require caring enough about the problem to recognize your own contributions and biases and then change yourself to be better. And I don't think faculty care about many things enough to respond by recognizing their failures and changing their behavior.

Finally, another fun quote that stood out to me in the racist AI article:

> In retrospect, expecting news to be safe from algorithmic bias was rather a lot to hope for.

This reminds me of the current news about the white woman who got shot by a black police officer, and how the public response and media coverage of her situation is so different than that of the recent police murder of Charleena Lyles. I can't find the most pertinent comparison that I saw earlier, but it was essentially a screenshot of a Fox news headline saying "Rest in peace Justine" juxtaposed with a "No results for Charleena Fox" screen on Twitter.

For more reading on this, I encourage you to google Charleena and Justine's stories, and pay attention to the language and sources covering them. [This public facebook post](https://www.facebook.com/kira.jackson.5030/posts/1385875234823102) is a good place to start learning what to pay attention to, but there are so many others!  

## Update (January 12, 2018)

Check out my [follow-up post](/posts/2018/01/caring-about-diversity-is-not-that-hard-part-2) with some nuance on my "faculty don't care enough" stance.
